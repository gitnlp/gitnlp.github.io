<!DOCTYPE html>
<html lang="en">

<head>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-71156606-1');
    </script>
    <meta charset="utf-8" />
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>Advancing AGI: Adaptable & Generalizable Intelligence</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <link rel="stylesheet" type="text/css" href="./assets/css/main.css" />

    <script type="text/javascript">document.documentElement.className = 'js';</script>
    <meta name="referrer" content="no-referrer-when-downgrade" />

    <meta property="og:site_name" content="MSR AGI" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Advancing AGI: Adaptable & Generalizable Intelligence" />
    <meta property="og:description" content="Our mission is to advance artificial adaptable & generalizable intelligence." />
    
    <meta property="og:description"
        content="Our mission is to advance artificial generalizable intelligence." />
    <meta property="article:modified_time" content="2019-03-07T02:01:09.000Z" />
    <meta property="og:image:width" content="3200" />
    <meta property="og:image:height" content="1800" />

    <meta name="generator" content="Ghost 5.12" />
    <style id="gh-members-styles">
        .gh-post-upgrade-cta-content,
        .gh-post-upgrade-cta {
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            text-align: center;
            width: 100%;
            color: #ffffff;
            font-size: 16px;
        }

        .gh-post-upgrade-cta-content {
            border-radius: 8px;
            padding: 40px 4vw;
        }

        .gh-post-upgrade-cta h2 {
            color: #ffffff;
            font-size: 28px;
            letter-spacing: -0.2px;
            margin: 0;
            padding: 0;
        }

        .gh-post-upgrade-cta p {
            margin: 20px 0 0;
            padding: 0;
        }

        .gh-post-upgrade-cta small {
            font-size: 16px;
            letter-spacing: -0.2px;
        }

        .gh-post-upgrade-cta a {
            color: #ffffff;
            cursor: pointer;
            font-weight: 500;
            box-shadow: none;
            text-decoration: underline;
        }

        .gh-post-upgrade-cta a:hover {
            color: #ffffff;
            opacity: 0.8;
            box-shadow: none;
            text-decoration: underline;
        }

        .gh-post-upgrade-cta a.gh-btn {
            display: block;
            background: #ffffff;
            text-decoration: none;
            margin: 28px 0 0;
            padding: 8px 18px;
            border-radius: 4px;
            font-size: 16px;
            font-weight: 600;
        }

        .gh-post-upgrade-cta a.gh-btn:hover {
            opacity: 0.92;
        }
    </style>
    <script defer src="./assets/js/cards.min.js"></script>
    <style>
        :root {
            --ghost-accent-color: #15171A;
        }
        tag {
            /* color: -webkit-link; */
            font-style: italic;
            font-size: 16px;
            color: black;
            /* color: white;
            background-color: #264653!important;
            font-weight: 600;
            padding: 0px 3px 0 3px;
            margin-right: 5px; */
        }
    </style>
    <link rel="stylesheet" type="text/css" href="./assets/css/cards.min.css">
</head>

<body>

    <header>
        <nav class="nav container" data-url="/blog/">
            <div class="nav-row row align-items-center">
                <div class="d-none d-sm-block col-sm nav-symbol-wrap">
                    <a href="./index.html"> Home </a>
                </div>
                <div class="col col-sm-auto">
                    <ul class="d-flex flex-row align-items-center justify-content-between small-caps">
                        <div class="d-sm-none nav-symbol-wrap">
                        </div>
                        
                        <!--li class="ml-sm-1.75" style="margin-top:0.5px"><a class="nav-link active" href="overview.html"
                                data-slug="research">Overview</a></li-->

                        <li class="ml-sm-1.75" style="margin-top:0.5px"><a class="nav-link" href="research.html"
                            data-slug="research">Research</a></li>

                    <li class="ml-sm-1.75" style="margin-top:0.5px"><a class="nav-link" href="blog.html"
                            data-slug="blog">Blog</a></li>

                    <li class="ml-sm-1.75" style="margin-top:0.5px"><a class="nav-link" href="about.html"
                            data-slug="about">About</a></li>
                    </ul>
                </div>
            </div>
        </nav>

    </header>
    <div class="container mt-4">
        <h2 class="mb-2">Research Highlights</h2>
        
        <p style="padding-bottom:40px">A summary of our recent mission-focused research agenda.</p>
        
        <!--h3 class="mb-2"><b>Advancing AGI</b></h3-->
        <p style="padding-bottom:10px"><b>Advancing AGI</b></p>
        <p>Our long-term mission is to advance artificial general (adaptable & generalizable) intelligence, focusing on the <i>generality</i>, <i>generalizability</i>, and <i>adaptability</i> of AI. </p>
        <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>General-purpose Foundation Model</i></p>
        <p>
           Among others, we are committed to the research and development of a <i>general-purpose foundation model</i> that can be systematically generalized and adapted to a broad set of tasks with <b>general modalities</b> as input.
         </p>
         
         <br>
         <p style="padding-top:0px; padding-bottom:10px"><i>LLM / MLLM (Multimodal LLM)</i></p>
         
         <p>
         <div style="padding-left:20px; padding-top:10px">
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2302.14045">(<font color="red">Kosmos-1</font>) Language Is Not All You Need: Aligning Perception with Language Models</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2206.06336">(MetaLM) Language Models are General-Purpose Interfaces</a></h5>
         </div>
         </p>
         
        <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>Foundation Models Across Tasks, Languages, and Modalities</i></p>
        <p>
           Our research has been pushing the <b>#TheBigConvergence</b> of <i>foundation models</i> and <i>large-scale pre-training across tasks, languages, and modalities</i>.
        </p>
        
        <p>
         <div style="padding-left:20px; padding-top:10px">
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2302.14045">(<font color="blue">Kosmos-1</font>) Language Is Not All You Need: Aligning Perception with Language Models</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2301.02111">(<font color="blue">VALL-E</font>) Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</a></h5>
         <p style="height: 5px"></p>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2208.10442">(BEiT-3) <font color="blue">Image as a Foreign Language</font>: BEiT Pretraining for All Vision and Vision-Language Tasks</a>. <tag>CVPR'23</tag>.</h5>
         <p style="height: 5px"></p>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2208.06366">BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2106.08254">BEiT: BERT Pre-Training of Image Transformers.</a> <tag>ICLR'22 (<font color="blue"><a href="https://openreview.net/forum?id=p-BhZSz59o4">Oral</a></font>)</tag>.</h5>
         <p style="height: 5px"></p>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2106.16138">XLM-E: Cross-lingual Language Model Pre-training via ELECTRA.</a> <tag>ACL'22</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2104.08692">mT6: Multilingual Pretrained Text-to-Text Transformer with Translation Pairs.</a> <tag>EMNLP'21</tag>.</h5>
                  
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2007.07834">InfoXLM: An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training.</a> <tag>NAACL'21</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2002.12804">UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training.</a> <tag>ICML'20</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/1905.03197">(UniLM) Unified Language Model Pre-training for Natural Language Understanding and Generation.</a> <tag>NeurIPS'19</tag>.</h5>
         </div>
         </p>
        
        <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>Foundation Transformers</i></p>
        <p>
           Fundamental research to improve modeling <i>generality</i> and <i>capability</i> as well as training <i>stability</i> and <i>efficiency</i> for <b>Transformers at any scale</b>, and develop the next-generation general-purpose AI architecture.
        </p>
        
        <p>
         <div style="padding-left:20px; padding-top:10px">
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2211.13184"><font color="blue">TorchScale</font>: Transformers at Scale</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2212.10554">A Length-Extrapolatable Transformer</font></a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2210.06423">(Magneto) <font color="blue">Foundation Transformers</font></a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2203.00555">DeepNet: Scaling Transformers to 1,000 Layers</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2204.09179">On the Representation Collapse of Sparse Mixture of Experts.</a> <tag>NeurIPS'22</tag>.</h5>
         </div>
         </p>
         
         <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>LMOps</i></p>
        <p>
           General technology for <b>enabling AI capabilities w/ (M)LLMs</b>. 
        </p>

<div style="padding-left:15pt">
        <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>Prompt Intelligence</i></p>
        <p>
           Prompt as a new language of Foundation Models and Generative AI, and a new programming language and interface for Human-AI communication and collaboration. 
        </p>
        
        <p>
         <div style="padding-left:20px; padding-top:10px">
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2212.09611">(<font color="blue">Promptist</font>) Optimizing Prompts for Text-to-Image Generation</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2212.06713">Structured Prompting: Scaling In-Context Learning to 1,000 Examples</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2212.00616"><font color="blue">Extensible Prompts</font> for Language Models</a></h5>
         </div>
         </p>

        <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>Democratizing Foundation Models</i></p>
        <p>
           Research and development of effective and efficient approaches to deploying large AI (foundation) models in practice. 
        </p>
        
        <p>
         <div style="padding-left:20px; padding-top:10px">
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2205.10350">Lossless Acceleration for Seq2seq Generation with Aggressive Decoding</a></h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2202.07959">EdgeFormer: A Parameter-Efficient Transformer for On-Device Seq2seq Generation.</a> <tag>EMNLP'22</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2106.08226">(xTune) Consistency Regularization for Cross-Lingual Fine-Tuning.</a> <tag>EMNLP'21</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2012.15828">MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers.</a> <tag>ACL'21</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2002.10957">MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers</a>.</a> <tag>NeurIPS'22</tag>.</h5>
         </div>
         </p>
         
         </div>
         
        <br>
        
        <br>
        <p style="padding-bottom:10px"><b>Verticals</b></p>
        <p>Our research also pushes disruptive technologies for vertical domains and/or tasks. </p>
        <br>
        
        <p style="padding-top:0px; padding-bottom:10px"><i>Revolutionizing Document AI</i></p>
        <p>
           Our pioneering research on multimodal document foundation models for technology evolution of Document AI. 
        </p>
        
        <p>
         <div style="padding-left:20px; padding-top:10px">
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2204.08387">LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking.</a> <tag>ACM MM'22</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2012.14740">LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding.</a> <tag>ACL'21</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/1912.13318">LayoutLM: Pre-training of Text and Layout for Document Image Understanding.</a> <tag>KDD'20</tag>.</h5>
         
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2104.08836">LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding.</a> <tag>ACL'21</tag>.</h5>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2203.02378">DiT: Self-supervised Pre-training for Document Image Transformer.</a> <tag>ACM MM'22</tag>.</h5>
         
         <p style="height: 5px"></p>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2110.08518">MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding.</a> <tag>ACL'22</tag>.</h5>
             
         <p style="height: 5px"></p>
         <h5 class="medium-xsmall-copy balance-text mb-1/12"><a href="https://arxiv.org/abs/2109.10282">TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models.</a> <tag>AAAI'23</tag>.</h5>
         </div>
         </p>

    </div>


    <footer class="footer container medium-xsmall-copy line-height-1.6">

        <div class="row align-items-center mb-0.125">
            <div class="col-12 col-md mb-0.5">
                <a class="fade" style="margin-top:1px" href="/">&copy; 2022</a>
            </div>
        </div>
    </footer>

    <script type="text/javascript" src="./assets/js/main.min.js"></script>


</body>

</html>
